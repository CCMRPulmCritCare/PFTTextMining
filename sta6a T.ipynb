{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2712ae58-1b47-4911-bac7-87c37d77c69f",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8a811dc-8a0f-451b-af07-dc60a3e5f271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370c6a5-14d7-4b0f-a49f-d6c59b9d5847",
   "metadata": {},
   "source": [
    "## Step 2: Import Dataset and Perform Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d69c24a-1001-42ef-9463-29720c6dab10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in dataset from Excel\n",
    "df = pd.read_excel('[Insert Directory Here]/[Insert File Name Here].xlsx') # Portland, OR\n",
    "\n",
    "# Convert ReportText to string and remove carriage returns and extra spacing between words\n",
    "df['ReportText'] = df['ReportText'].astype('str')\n",
    "df['ReportText'] = df['ReportText'].str.replace(r'\\s+', ' ', regex=True).str.replace(r'\\n+', ' ', regex=True)\n",
    "\n",
    "# Convert PFT date column to date data type\n",
    "df['pft_date'] = df['pft_date'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c7750-ee0a-4553-a103-a2949d1f2d03",
   "metadata": {},
   "source": [
    "## Step 3: Create snippet extraction function after identifying snippet in notes by checking a random sample of 100 notes with:\n",
    "\n",
    "```\n",
    "n = 1\n",
    "for index,row in df.sample(frac=1)[:100].iterrows():\n",
    "    print(f\"Row Number: {n}\")\n",
    "    print(f\"Note: {row['ReportText']}\")\n",
    "    print('-'*100)\n",
    "    n+=1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfa32a77-500c-4b4a-8ce8-fb87f5206f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create snippet based on template start phrase\n",
    "def extract_fev1_context(text):\n",
    "    pattern = re.compile(r'.{0,150}[Insert Your Snippet Here].{0,250}', re.IGNORECASE)\n",
    "    matches = pattern.findall(text)\n",
    "    return ' '.join(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982500ee-50ff-4460-ac4c-b3a42a36247b",
   "metadata": {},
   "source": [
    "## Step 4: Run the `ReportText` column through the function to generate a new `Snippet` column containing each note's snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea038e59-4646-49ba-a617-166ae63713ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy(deep = True)\n",
    "df['Snippet'] = df['ReportText'].apply(extract_fev1_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2bab4f-93bb-4883-a099-182c04945fad",
   "metadata": {},
   "source": [
    "## Step 5: Initialize new dataframe containing only rows that have a snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a91204f6-d80a-4ebf-9e86-334d6717f552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notes_with_fev = df[df['Snippet'] != ''].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f30c2-a0c5-4427-9c26-ccc4da739e28",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### You can validate snippets with the following code:\n",
    "```\n",
    "n = 1\n",
    "for index,row in notes_with_fev.sample(frac=1)[:100].iterrows():\n",
    "    print(f\"Row Number: {n}\")\n",
    "    print(f\"Note: {row['ReportText']}\")\n",
    "    print(row['Snippet'])\n",
    "    print('-'*100)\n",
    "    n+=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a6381-ddef-4287-aa6a-f20c85d71241",
   "metadata": {},
   "source": [
    "## Step 6: Initialize the PFT Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b6072d0-8060-4af7-a6ed-d151a3c0548d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_fev1(row):\n",
    "    # Initialize variables\n",
    "    fev1_abs_post = []\n",
    "    fev1_abs_pre = []\n",
    "    fev1_fvc_pre = []\n",
    "    fev1_fvc_post = []\n",
    "    fev1_perc_predicted_post = []\n",
    "    fev1_perc_predicted_pre = []\n",
    "    \n",
    "    text = row['Snippet']\n",
    "    # Pred-pre Actual-pre %Pred-pre Actual-post %Chng SPIROMETRY FVC (L) 4.44 2.21 49 2.80 26 FEV1 (L) 3.43 0.67 19 0.77 15\n",
    "    # FEV1 absolute pre BD 1\n",
    "    fev1_vol_pre = re.compile(r'FEV1(?![/FVC])\\s\\(L\\)\\s\\d*\\.\\d+\\s(\\d*\\.\\d+)', re.IGNORECASE)\n",
    "    fev1_vol_results_pre = fev1_vol_pre.findall(text)\n",
    "    \n",
    "    if fev1_vol_results_pre:\n",
    "        fev1_abs_pre.append(fev1_vol_results_pre)\n",
    "        \n",
    "    # FEV1 absolute post BD 1\n",
    "    fev1_vol_post = re.compile(r'FEV1(?![/FVC])\\s\\(L\\)\\s\\d*\\.\\d+\\s\\d*\\.\\d+\\s\\d{2,3}\\s(\\d*\\.\\d+)', re.IGNORECASE)\n",
    "    fev1_vol_results_post = fev1_vol_post.findall(text)\n",
    "    \n",
    "    if fev1_vol_results_post:\n",
    "        fev1_abs_post.append(fev1_vol_results_post)\n",
    "        \n",
    "    # Actual-pre LLN ZScore %Pred-pre Actual-post %Pred VolChg %Chg ... FEV1-L 1.74 2.52 -3.04 51 1.66 -0.08 49 -4\n",
    "    # FEV1 abs value pre BD pattern 2\n",
    "    fev1_vol_pre_2 = re.compile(r'FEV1-L\\s(\\d*\\.\\d+)', re.IGNORECASE)\n",
    "    fev1_vol_results_pre_2 = fev1_vol_pre_2.findall(text)\n",
    "    \n",
    "    if fev1_vol_results_pre_2:\n",
    "        fev1_abs_pre.append(fev1_vol_results_pre_2)\n",
    "        \n",
    "    # FEV1 abs value post BD 2\n",
    "    fev1_vol_post_2 = re.compile(r'FEV1-L\\s\\d*\\.\\d+\\s\\d*\\.\\d+\\s-?\\d*\\.\\d+\\s\\d{2,3}\\s(\\d*\\.\\d+)', re.IGNORECASE)\n",
    "    fev1_vol_results_post_2 = fev1_vol_post_2.findall(text)\n",
    "    \n",
    "    if fev1_vol_results_post_2:\n",
    "        fev1_abs_post.append(fev1_vol_results_post_2)\n",
    "        \n",
    "    # FEV1/FVC pre BD 1 (Pred-pre Actual-pre %Pred-pre Actual-post)FEV1/FVC (%) 76 43 56 43\n",
    "    fev1_fvc_pre_1 = re.compile(r'FEV1/FVC\\s\\(%\\)\\s\\d{2}\\s(\\d{2})', re.IGNORECASE)\n",
    "    fev1_fvc_pre_1_results = fev1_fvc_pre_1.findall(text)\n",
    "    \n",
    "    if fev1_fvc_pre_1_results:\n",
    "        fev1_fvc_pre.append(fev1_fvc_pre_1_results)\n",
    "\n",
    "    # FEV1/FVC post BD 1 (Pred-pre Actual-pre %Pred-pre Actual-post)FEV1/FVC (%) 76 43 56 43\n",
    "    fev1_fvc_post_1 = re.compile(r'FEV1/FVC\\s\\(%\\)\\s\\d{2}\\s\\d{2}\\s\\d{2}\\s(\\d{2})', re.IGNORECASE)\n",
    "    fev1_fvc_post_1_results = fev1_fvc_post_1.findall(text)\n",
    "    \n",
    "    if fev1_fvc_post_1_results:\n",
    "        fev1_fvc_post.append(fev1_fvc_post_1_results)\n",
    "        \n",
    "    # FEV1/FVC pre BD 2 (Actual-pre LLN ZScore %Pred-pre Actual-post %Pred VolChg %Chg FEV1/FVC-% 81 64 0.58 105 89 116 10)\n",
    "    fev1_fvc_pre_2 = re.compile(r'FEV1/FVC-%\\s(\\d{2})', re.IGNORECASE)\n",
    "    fev1_fvc_pre_2_results = fev1_fvc_pre_2.findall(text)\n",
    "    \n",
    "    if fev1_fvc_pre_2_results:\n",
    "        fev1_fvc_pre.append(fev1_fvc_pre_2_results)\n",
    "        \n",
    "    # FEV1/FVC post BD 2 (Actual-pre LLN ZScore %Pred-pre Actual-post %Pred VolChg %Chg FEV1/FVC-% 81 64 0.58 105 89 116 10)\n",
    "    fev1_fvc_post_2 = re.compile(r'FEV1/FVC-%\\s\\d{2}\\s\\d{2}\\s-?\\d*\\.\\d+\\s\\d{2,3}(\\d{2})', re.IGNORECASE)\n",
    "    fev1_fvc_post_2_results = fev1_fvc_post_2.findall(text)\n",
    "    \n",
    "    if fev1_fvc_post_2_results:\n",
    "        fev1_fvc_post.append(fev1_fvc_post_2_results) \n",
    "    \n",
    "    \n",
    "    # FEV1 percent pred pre pattern 1 (Pred-pre Actual-pre %Pred-pre Actual-post %Chng FEV1 (L) 4.09 1.95 47 2.41 23)\n",
    "    fev1_perc_pred_pre = re.compile(r'FEV1(?![/FVC])\\s\\(L\\)\\s\\d*\\.\\d+\\s\\d*\\.\\d+\\s(\\d{2,3})', re.IGNORECASE)\n",
    "    fev1_perc_pred_pre_results = fev1_perc_pred_pre.findall(text)\n",
    "\n",
    "    if fev1_perc_pred_pre_results:\n",
    "        fev1_perc_predicted_pre.append(fev1_perc_pred_pre_results)\n",
    "        \n",
    "    # FEV1 percent pred pre pattern 2 (Actual-pre LLN ZScore %Pred-pre Actual-post %Pred-post VolChg %Chg FEV1-L 2.31 3.32 -3.22 53 2.79 0.48 64 20)\n",
    "    fev1_perc_pred_pre_2 = re.compile(r'FEV1-L\\s\\d*\\.\\d+\\s\\d*\\.\\d+\\s-?\\d*\\.\\d+\\s(\\d{2,3})', re.IGNORECASE)\n",
    "    fev1_perc_pred_pre_results_2 = fev1_perc_pred_pre_2.findall(text)\n",
    "\n",
    "    if fev1_perc_pred_pre_results_2:\n",
    "        fev1_perc_predicted_pre.append(fev1_perc_pred_pre_results_2)\n",
    "        \n",
    "    # FEV1 percent pred post pattern (Actual-pre LLN ZScore %Pred-pre Actual-post %Pred-post VolChg %Chg FEV1-L 2.31 3.32 -3.22 53 2.79 0.48 64 20)\n",
    "    fev1_perc_pred_post = re.compile(r'FEV1-L\\s\\d*\\.\\d+\\s\\d*\\.\\d+\\s-?\\d*\\.\\d+\\s\\d{2,3}\\s(\\d*\\.\\d+)', re.IGNORECASE)\n",
    "    fev1_perc_pred_post_results = fev1_perc_pred_post.findall(text)\n",
    "\n",
    "    if fev1_perc_pred_post_results:\n",
    "        fev1_perc_predicted_post.append(fev1_perc_pred_post_results)  \n",
    "    \n",
    "    # Qualitative variables; hi  \n",
    "    fev1_qual_hi = []\n",
    "    fev1_qual_hi_pattern = re.compile(r'(FEV1 is normal|normal spirometry|spirometry is normal|normal pfts|no obstruction)', re.IGNORECASE)                                  \n",
    "    fev1_qual_hi_matches = fev1_qual_hi_pattern.findall(text)\n",
    "    \n",
    "    for match in fev1_qual_hi_matches:\n",
    "        if len(match) > 0:\n",
    "            fev1_qual_hi.append(match)\n",
    "    \n",
    "    # Qualitative variables low: Q what to include in negative FEV descriptors (air trapping, dyspnea?)\n",
    "    fev1_qual_lo = []\n",
    "    fev1_qual_lo_pattern = re.compile(r'((?<!no )obstruction)', re.IGNORECASE)\n",
    "    fev1_qual_lo_matches = fev1_qual_lo_pattern.findall(text)\n",
    "        \n",
    "    for match in fev1_qual_lo_matches:\n",
    "        match = match.lower()\n",
    "        if len(match) > 0 and match not in fev1_qual_lo:\n",
    "            fev1_qual_lo.append(match)\n",
    "    \n",
    "    \n",
    "    if len(fev1_qual_lo) != 0:\n",
    "        fev1_qual_hi = []\n",
    "    \n",
    "    return pd.Series({'FEV1_Abs_Post': fev1_abs_post if fev1_abs_post else None,\n",
    "                      'FEV1_Abs_Pre': fev1_abs_pre if fev1_abs_pre else None,\n",
    "                      'FEV1_FVC_Pre': fev1_fvc_pre if fev1_fvc_pre else None,\n",
    "                      'FEV1_FVC_Post': fev1_fvc_post if fev1_fvc_post else None,\n",
    "                      'FEV1_Perc_Pred_Post': fev1_perc_predicted_post if fev1_perc_predicted_post else None,\n",
    "                     'FEV1_Perc_Pred_Pre': fev1_perc_predicted_pre if fev1_perc_predicted_pre else None,\n",
    "                      'FEV1_Qual_High': fev1_qual_hi if fev1_qual_hi else None,\n",
    "                      'FEV1_Qual_Low': fev1_qual_lo if fev1_qual_lo else None})\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d01236-e1ba-4521-b2aa-b7f7a827d2c3",
   "metadata": {},
   "source": [
    "## Step 6: Run dataframe through the PFT extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4bed5421-cd5b-481b-8d70-c52387c1ba03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = notes_with_fev.join(notes_with_fev.apply(classify_fev1, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67365c9-ca84-41ce-81d6-27547c6e5baf",
   "metadata": {},
   "source": [
    "## Step 7: Extract values from FEV1 % predicted and FEV1:FVC pre-BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9567f712-7af4-47c7-bed0-c8ad7efbbd7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_value(nested_list):\n",
    "    if nested_list is not None:\n",
    "        return int(nested_list[0][0])\n",
    "\n",
    "# Create new variables 'FEV1_Perc_Pred' and 'fev1_fvc' to hold extracted quantitative values\n",
    "results['FEV1_Perc_Pred'] = results['FEV1_Perc_Pred_Pre'].apply(extract_value)\n",
    "results['fev1_fvc'] = results['FEV1_FVC_Pre'].apply(extract_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbadc26f-7e1c-435f-87dd-af516fdbda88",
   "metadata": {},
   "source": [
    "## Step 8: Create mapping functions to map quantitative values to the standard clinical definitions of obstruction and severity of obstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07e04816-b9c8-4f23-aa2a-c26ce1c68f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fev1_severity(value):\n",
    "    if value >= 80:\n",
    "        return \"Normal\"\n",
    "    if 70 <= value <= 79:\n",
    "        return \"Mild\"\n",
    "    if 60 <= value <= 69:\n",
    "        return \"Moderate\"\n",
    "    if 50 <= value <= 59:\n",
    "        return \"Moderately Severe\"\n",
    "    if 35 <= value < 50:\n",
    "        return \"Severe\"\n",
    "    if value < 35:\n",
    "        return \"Very Severe\"\n",
    "    \n",
    "def obstruction(value):\n",
    "    if value >= 70:\n",
    "        return \"Normal\"\n",
    "    if value < 70:\n",
    "        return \"Reduced\"\n",
    "\n",
    "# Create new variables 'FEV1_Severity' and 'Obstruction' by running the FEV1 % predicted and FEV1:FVC variables through the mapping functions    \n",
    "results['FEV1_Severity'] = results['FEV1_Perc_Pred'].map(fev1_severity)\n",
    "results['Obstruction'] = results['fev1_fvc'].map(obstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339aa52f-20d2-4b05-87c8-5c08f10dfc31",
   "metadata": {},
   "source": [
    "## Step 9: Drop duplicate rows or rows missing extracted PFT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d7394d-ee75-4814-884e-68d53f7bbf9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List columns to define on which variables you would like to drop duplicates\n",
    "list_cols = ['Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low']\n",
    "\n",
    "# Drop rows that have no extracted PFT values\n",
    "results = results.dropna(subset = list_cols, how = 'all')\n",
    "\n",
    "# Convert columns in list_cols to string\n",
    "for col in list_cols:\n",
    "    results[col] = results[col].apply(lambda x: str(x))\n",
    "\n",
    "# Drop duplicates of PFT results based on columns of interest + PatientID and PFT date\n",
    "results = results.drop_duplicates(subset = ['PatientICN', 'pft_date', 'Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low'])\n",
    "\n",
    "# Replace cells with 'None' values to empty string for ease of readability in the output Excel file\n",
    "results.replace('None','',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c7b23-1401-478a-bac6-029b3af81166",
   "metadata": {},
   "source": [
    "## Step 10: Merge rows from same PFT with multiple notes containing values for different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de0c64d2-0321-4ba4-8ad9-bea3a8ba08e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define columns that will keep the max value if the two rows being merged have different values for.\n",
    "columns_to_max = ['PatientSID', 'Obstruction', 'FEV1_Severity','FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low']\n",
    "\n",
    "# This function ensures that we don't lose one of the snippets upon merge, but rather append them together\n",
    "def concatenate_strings(series):\n",
    "    return ''.join(series.unique())\n",
    "\n",
    "# Define aggregation function to keep the max value for columns that both have data across the rows\n",
    "agg_funcs = {col: 'max' for col in columns_to_max}\n",
    "\n",
    "# Create concatenated snippets for merged rows (instead of taking the \"max\" snippet value)\n",
    "agg_funcs['Snippet'] = concatenate_strings\n",
    "\n",
    "# Regenerate dataframe with collapsed rows for identical PFTs with multiple notes\n",
    "results = results.groupby(['PatientICN','pft_date'], sort = False).agg(agg_funcs).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821bd66-ffff-43bb-92d0-383d7c06183e",
   "metadata": {},
   "source": [
    "## Step 11: Export data to Excel for validation/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef44d04a-1d18-4ed4-9bbf-b491288d4281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select columns to export\n",
    "columns_to_export = ['Snippet', 'PatientICN', 'PatientSID', 'pft_date', 'Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low']\n",
    "\n",
    "# Define desired output directory, file name, and file path\n",
    "output_dir = '[Insert Your Directory Here]/'\n",
    "file_name = '[Insert Filename Here].xlsx'\n",
    "full_path = output_dir + file_name\n",
    "to_export = results\n",
    "\n",
    "# Export data as .xlsx file\n",
    "to_export.to_excel(full_path, columns = columns_to_export, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a494f3a-6896-454a-97c5-d32452c59b40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
