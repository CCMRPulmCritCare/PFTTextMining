{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a12ea23-f16d-4042-b265-266286991f34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a49a0aa-5aa8-4267-a8ff-835bfe05cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a143fb3-af85-4850-92b6-709e156b72e1",
   "metadata": {},
   "source": [
    "## Step 2: Import Dataset and Perform Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409d22d2-14e4-428f-8f0d-eaae0b3adfbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in dataset from Excel\n",
    "df = pd.read_excel('[Insert Your Directory Here]/[Insert File Name Here].xlsx')\n",
    "\n",
    "# Convert ReportText to string and remove carriage returns and extra spacing between words\n",
    "df['ReportText'] = df['ReportText'].astype('str')\n",
    "df['ReportText'] = df['ReportText'].str.replace(r'\\s+', ' ', regex=True).str.replace(r'\\n+', ' ', regex=True)\n",
    "\n",
    "# Convert PFT date column to date data type\n",
    "df['pft_date'] = df['pft_date'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd53f69-4078-4d0a-b16e-b52eb6a13ad8",
   "metadata": {},
   "source": [
    "## Step 3: Create snippet extraction function after identifying snippet in notes by checking a random sample of 100 notes with:\n",
    "\n",
    "```\n",
    "n = 1\n",
    "for index,row in df.sample(frac=1)[:100].iterrows():\n",
    "    print(f\"Row Number: {n}\")\n",
    "    print(f\"Note: {row['ReportText']}\")\n",
    "    print('-'*100)\n",
    "    n+=1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef67de6-2386-464e-8f69-c07a1b12405f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create snippet based on template start phrases\n",
    "def extract_fev1_context(text):\n",
    "    pattern = re.compile(r'.Spirometry Results.{0,1000}', re.IGNORECASE)\n",
    "    matches = pattern.findall(text)\n",
    "    return ' '.join(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da64f17-2a1a-43e3-95c2-a9523e74837d",
   "metadata": {},
   "source": [
    "## Step 4: Run the `ReportText` column through the function to generate a new `Snippet` column containing each note's snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519600a8-bf3d-4710-b2ea-1c2e0debb986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.copy(deep = True)\n",
    "df['Snippet'] = df['ReportText'].apply(extract_fev1_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8e703-4623-4c94-a25d-ba6ecbae212e",
   "metadata": {},
   "source": [
    "## Step 5: Initialize new dataframe containing only rows that have a snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "584fcdc7-7e90-4f97-bd85-3f04433a168b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notes_with_fev = df[df['Snippet'] != ''].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d78c90-6208-4a99-afc3-a64d31914ad2",
   "metadata": {},
   "source": [
    "## Step 6: Initialize the PFT Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16181774-78de-40e3-b8f8-053a2a078bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_fev1(row):\n",
    "    # Initialize variables\n",
    "    fev1_abs_pre = []\n",
    "    fev1_abs_post = []\n",
    "    fev1_perc_pred_pre = []\n",
    "    fev1_perc_pred_post = []\n",
    "    fev1_fvc_pre = []\n",
    "    fev1_fvc_post = []\n",
    "    \n",
    "    text = row['Snippet']\n",
    "    \n",
    "    # FEV1 abs pre BD absolute value matching pattern\n",
    "    fev1_abs_pre_pattern = re.compile(r'Baseline.*?FEV-1.*?\\d*\\.\\d+.*?(\\d*\\.\\d+)', re.IGNORECASE)\n",
    "    fev1_abs_pre_pattern_results = fev1_abs_pre_pattern.findall(text)\n",
    "    \n",
    "    if fev1_abs_pre_pattern_results:\n",
    "        fev1_abs_pre.append(fev1_abs_pre_pattern_results[0])\n",
    "        \n",
    "    # FEV1 abs post BD absolute value matching pattern\n",
    "    fev1_abs_post_pattern = re.compile(r'Post-Bronchodilator.*?FEV-1.*?\\d*\\.\\d+.*?(\\d*\\.\\d+)', re.IGNORECASE)\n",
    "    fev1_abs_post_pattern_results = fev1_abs_post_pattern.findall(text)\n",
    "    \n",
    "    if fev1_abs_post_pattern_results:\n",
    "        fev1_abs_post.append(fev1_abs_post_pattern_results[0])\n",
    "        \n",
    "        \n",
    "    # FEV1 % pred pre BD (Baseline FEV-1,% Predicted (whole number, e.g., 68): 50)\n",
    "    fev1_perc_pred_pre_pattern = re.compile(r'Baseline FEV-1\\,\\% Predicted.*?\\d{2}.*?(\\d{2})', re.IGNORECASE)\n",
    "    fev1_perc_pred_pre_pattern_results = fev1_perc_pred_pre_pattern.findall(text)\n",
    "    \n",
    "    if fev1_perc_pred_pre_pattern_results:\n",
    "        fev1_perc_pred_pre.append(fev1_perc_pred_pre_pattern_results[0])\n",
    "        \n",
    "    # FEV1 % pred post BD absolute value matching pattern\n",
    "    fev1_perc_pred_post_pattern = re.compile(r'Post-Bronchodilator.*?FEV-1, % predicted.*?\\d{2}.*?(\\d{2})', re.IGNORECASE)\n",
    "    fev1_perc_pred_post_pattern_results = fev1_perc_pred_post_pattern.findall(text)\n",
    "    \n",
    "    if fev1_perc_pred_post_pattern_results:\n",
    "        fev1_perc_pred_post.append(fev1_perc_pred_post_pattern_results[0])\n",
    "    \n",
    "    # FEV1/FVC pre BD absolute value matching pattern\n",
    "    fev1_fvc_pre_pattern = re.compile(r'Baseline.*?FEV-1/FVC.*?\\d{2}.*?(\\d{2})', re.IGNORECASE)\n",
    "    fev1_fvc_pre_pattern_results = fev1_fvc_pre_pattern.findall(text)\n",
    "    \n",
    "    if fev1_fvc_pre_pattern_results:\n",
    "        fev1_fvc_pre.append(fev1_fvc_pre_pattern_results[0])\n",
    "        \n",
    "    # FEV1/FVC post BD absolute value matching pattern\n",
    "    fev1_fvc_post_pattern = re.compile(r'Post-Bronchodilator.*?FEV-1/FVC.*?\\d{2}.*?(\\d{2})', re.IGNORECASE)\n",
    "    fev1_fvc_post_pattern_results = fev1_fvc_post_pattern.findall(text)\n",
    "    \n",
    "    if fev1_fvc_post_pattern_results:\n",
    "        fev1_fvc_post.append(fev1_fvc_post_pattern_results[0])\n",
    "    \n",
    "    # Qualitative variables; hi  \n",
    "    fev1_qual_hi = []\n",
    "    fev1_qual_hi_pattern = re.compile(r'(no evidence for airflow obstruction)', re.IGNORECASE)                                  \n",
    "    fev1_qual_hi_matches = fev1_qual_hi_pattern.findall(text)\n",
    "    \n",
    "    if fev1_qual_hi_matches:\n",
    "        fev1_qual_hi.append(fev1_qual_hi_matches)\n",
    "        \n",
    "    # Qualitative variables low\n",
    "    fev1_qual_lo = []\n",
    "    fev1_qual_lo_pattern = re.compile(r'(mild obstruction|moderate obstruction|modeately severe obstruction|modeately severe airflow obstruction|moderately severe obstruction|severe obstruction|very severe obstruction)', re.IGNORECASE)\n",
    "    fev1_qual_lo_matches = fev1_qual_lo_pattern.findall(text)\n",
    "        \n",
    "    if fev1_qual_lo_matches:\n",
    "        fev1_qual_lo.append(fev1_qual_lo_matches)\n",
    "\n",
    "    \n",
    "    return pd.Series({'FEV1_Abs_Pre': fev1_abs_pre if fev1_abs_pre else None,\n",
    "                      'FEV1_Abs_Post': fev1_abs_post if fev1_abs_post else None,\n",
    "                      'FEV1_Perc_Pred_Pre': fev1_perc_pred_pre if fev1_perc_pred_pre else None,\n",
    "                      'FEV1_Perc_Pred_Post': fev1_perc_pred_post if fev1_perc_pred_post else None,\n",
    "                      'FEV1_FVC_Pre': fev1_fvc_pre if fev1_fvc_pre else None,\n",
    "                      'FEV1_FVC_Post': fev1_fvc_post if fev1_fvc_post else None,\n",
    "                      'FEV1_Qual_High': fev1_qual_hi if fev1_qual_hi else None,\n",
    "                      'FEV1_Qual_Low': fev1_qual_lo if fev1_qual_lo else None\n",
    "                     })\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27611f-77cf-4cfb-be4d-bdcacd9f8227",
   "metadata": {},
   "source": [
    "## Step 6: Run dataframe through the PFT extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93af29ce-db37-45e8-9d17-81eb067660d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = notes_with_fev.join(notes_with_fev.apply(classify_fev1, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155f3ec-d792-4606-910e-a63659a09e84",
   "metadata": {},
   "source": [
    "## Step 7: Extract values from FEV1 % predicted, FEV1:FVC pre-BD, and qualitative variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1356baf-8bea-4095-95f4-68fde0609c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_value(nested_list):\n",
    "    if nested_list is not None:\n",
    "        return int(nested_list[0])\n",
    "\n",
    "# Create new variables 'FEV1_Perc_Pred' and 'fev1_fvc' to hold extracted quantitative values\n",
    "results['FEV1_Perc_Pred'] = results['FEV1_Perc_Pred_Pre'].apply(extract_value)\n",
    "results['fev1_fvc'] = results['FEV1_FVC_Pre'].apply(extract_value)\n",
    "\n",
    "def extract_fev1_qualitative(nested_list):\n",
    "    if nested_list is not None:\n",
    "        return str(nested_list[0][0])\n",
    "\n",
    "# Create new variables to hold qualitative data\n",
    "results['fev1_qual_neg'] = results['FEV1_Qual_Low'].apply(extract_fev1_qualitative)\n",
    "results['fev1_qual_pos'] = results['FEV1_Qual_High'].apply(extract_fev1_qualitative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c53aee-8dcb-4290-b10f-4e3bf851a540",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 8: Create mapping functions to map quantitative values to the standard clinical definitions of obstruction and severity of obstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3ff00e6-2b65-49a0-8bb3-06224b1df583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create mapping function\n",
    "def fev1_severity(value):\n",
    "    if value >= 80:\n",
    "        return \"Normal\"\n",
    "    if 70 <= value <= 79:\n",
    "        return \"Mild\"\n",
    "    if 60 <= value <= 69:\n",
    "        return \"Moderate\"\n",
    "    if 50 <= value <= 59:\n",
    "        return \"Moderately Severe\"\n",
    "    if 35 <= value < 50:\n",
    "        return \"Severe\"\n",
    "    if value < 35:\n",
    "        return \"Very Severe\"\n",
    "    \n",
    "def obstruction(value):\n",
    "    if value >= 70:\n",
    "        return \"Normal\"\n",
    "    if value < 70:\n",
    "        return \"Reduced\"\n",
    "\n",
    "# Create new variables 'FEV1_Severity' and 'Obstruction' by running the FEV1 % predicted and FEV1:FVC variables through the mapping functions\n",
    "results['FEV1_Severity'] = results['FEV1_Perc_Pred'].map(fev1_severity)\n",
    "results['Obstruction'] = results['fev1_fvc'].map(obstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a961143-963d-468f-b1a0-8547558ce809",
   "metadata": {},
   "source": [
    "## Step 9a: Impute FEV1 severity values from qualitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ac50f25-d77f-4772-958e-e941bb362d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fev1_severity_from_qual(row):\n",
    "    if row['FEV1_Severity'] is None and row['fev1_qual_pos'] in ['Normal spirometry', 'normal spirometry']:\n",
    "        return \"Normal\"\n",
    "    if row['FEV1_Severity'] is None and row['fev1_qual_neg'] == 'Mild Obstruction':\n",
    "        return \"Mild\"\n",
    "    elif row['FEV1_Severity'] is None and  row['fev1_qual_neg'] == 'Moderate Obstruction':\n",
    "        return \"Moderate\"\n",
    "    elif row['FEV1_Severity'] is None and row['fev1_qual_neg'] in ['Moderately Severe Obstruction', 'Modeately severe obstruction', 'Modeately severe airflow obstruction']:\n",
    "        return \"Moderately Severe\"\n",
    "    elif row['FEV1_Severity'] is None and row['fev1_qual_neg'] not in ['Moderately Severe Obstruction', 'Modeately severe obstruction', 'Modeately severe airflow obstruction'] and row['fev1_qual_neg'] == 'Severe Obstruction':\n",
    "        return \"Severe\"\n",
    "    elif row['FEV1_Severity'] is None and row['fev1_qual_neg'] not in ['Moderately Severe Obstruction', 'Modeately severe obstruction', 'Modeately severe airflow obstruction'] and row['fev1_qual_neg'] != 'Severe Obstruction' and row['fev1_qual_neg'] == 'Very Severe Obstruction':\n",
    "        return \"Very Severe\"\n",
    "    else:\n",
    "        return row['FEV1_Severity']\n",
    "\n",
    "# If quantitative data is missing for FEV1 % predicted, use available qualitative data to map value\n",
    "results['FEV1_Severity'] = results.apply(fev1_severity_from_qual, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5381dd96-5856-46c0-a233-9ebd75553705",
   "metadata": {},
   "source": [
    "## Step 9b: Impute obstruction values from qualitative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "697bf4a4-3460-4b79-b94a-9654b70ca70d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def obstruction_from_qual(row):\n",
    "    if row['Obstruction'] is None and row['fev1_qual_pos'] in ['No obstructive ventilatory defect', 'no obstructive ventilatory defect', 'Normal spirometry', 'No Obstruction', 'no obstruction', 'PFTs do not show obvious signs of obstructive disease']:\n",
    "        return \"Normal\"\n",
    "    if row['Obstruction'] is None and row['fev1_qual_neg'] is not None:\n",
    "        return \"Reduced\"\n",
    "    else:\n",
    "        return row['Obstruction']\n",
    "    \n",
    "# If quantitative data is missing for Obstruction, use qualitative data to map value\n",
    "results['Obstruction'] = results.apply(obstruction_from_qual, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1331c75-56d0-4f0a-8a5d-04d7f1acf010",
   "metadata": {},
   "source": [
    "## Step 10: Drop duplicate rows or rows missing extracted PFT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2945b16-82b5-40ff-9c06-4594acfcb083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List columns to define on which variables you would like to drop duplicates\n",
    "list_cols = ['Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_FVC_Post', 'FEV1_Perc_Pred_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low']\n",
    "\n",
    "# Drop rows that have no extracted PFT values\n",
    "results = results.dropna(subset = list_cols, how = 'all')\n",
    "\n",
    "# Convert columns in list_cols to string\n",
    "for col in list_cols:\n",
    "    results[col] = results[col].apply(lambda x: str(x))\n",
    "\n",
    "# Drop duplicates of PFT results based on columns of interest + PatientID and PFT date\n",
    "results = results.drop_duplicates(subset = ['PatientICN', 'pft_date', 'Obstruction','FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_FVC_Post', 'FEV1_Perc_Pred_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low'])\n",
    "\n",
    "# Replace cells with 'None' values to empty string for ease of readability in the output Excel file\n",
    "results.replace('None','',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd049f05-5c0c-4799-84ad-bfeb73c54117",
   "metadata": {},
   "source": [
    "## Step 11: Merge rows from same PFT with multiple notes containing values for different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf9b366c-3d3e-4890-bc0b-5d840a6dfac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define columns that will keep the max value if the two rows being merged have different values for.\n",
    "columns_to_max = ['PatientSID', 'Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_FVC_Post', 'FEV1_Perc_Pred_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low']\n",
    "\n",
    "# This function ensures that we don't lose one of the snippets upon merge, but rather append them together\n",
    "def concatenate_strings(series):\n",
    "    return ''.join(series.unique())\n",
    "\n",
    "# Define aggregation function to keep the max value for columns that both have data across the rows\n",
    "agg_funcs = {col: 'max' for col in columns_to_max}\n",
    "\n",
    "# Create concatenated snippets for merged rows (instead of taking the \"max\" snippet value)\n",
    "agg_funcs['Snippet'] = concatenate_strings\n",
    "\n",
    "# Regenerate dataframe with collapsed rows for identical PFTs with multiple notes\n",
    "results = results.groupby(['PatientICN','pft_date'], sort = False).agg(agg_funcs).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0707117-6f52-4d86-bfa9-3056374d06f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define columns that will keep the max value if the two rows being merged have different values for.\n",
    "columns_to_export = ['Snippet', 'PatientICN', 'PatientSID', 'pft_date', 'Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_FVC_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low']\n",
    "\n",
    "# This function ensures that we don't lose one of the snippets upon merge, but rather append them together\n",
    "output_dir = '[Insert Directory Here]/'\n",
    "file_name = '[Insert File Name Here].xlsx'\n",
    "full_path = output_dir + file_name\n",
    "to_export = results.sort_values(by=['PatientICN', 'pft_date'])\n",
    "\n",
    "# Export data as .xslx file\n",
    "to_export.to_excel(full_path, columns = columns_to_export, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c11ea-5ad3-448e-9999-e4020971ffc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
