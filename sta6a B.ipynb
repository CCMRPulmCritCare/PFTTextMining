{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e92223-a32d-461e-ab0b-9752166240d5",
   "metadata": {},
   "source": [
    "## Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26835bf0-a328-4639-866d-1c80d22c4740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d7dc96-bca0-4024-955a-2b06dbaccf97",
   "metadata": {},
   "source": [
    "## Step 2: Import dataset and perform initial preprocessing steps\n",
    "##### The next piece of code accomplishes several important preprocessing steps. First, we read the dataset into a pandas dataframe from Excel. Next, we'll convert the ReportText column to string and convert any contiguous spaces or carriage returns to a single space. This transforms the ReportText column into a much more readable format for identifying PFT report templates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef00471f-1751-4124-bef0-8adb5bdd1966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import data from Excel to pandas dataframe. Important to include PatientICN, PFT date, and ReportText columns\n",
    "df = pd.read_excel('[Insert Directory Here]/[Insert File Name Here].xlsx')\n",
    "\n",
    "# Convert ReportText to string and remove carriage returns and extra spacing between words\n",
    "df['ReportText'] = df['ReportText'].astype('str')\n",
    "df['ReportText'] = df['ReportText'].str.replace(r'\\s+', ' ', regex=True).str.replace(r'\\n+', ' ', regex=True)\n",
    "\n",
    "# Convert PFT date column to date data type\n",
    "df['pft_date'] = df['pft_date'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216145a8-dde9-4ec8-9ac3-00d81bdf77b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Create function to generate snippets from notes\n",
    "##### In order to do identify templates, use the following code to investigate the a random sample of 100 notes with a record counter and '-'-' separator for readability. You must identify templates before moving onto the next step, where you create the function `extract_fev1_context()`. Feel free to add additional columns to the below loop for more thorough validation (e.g. PFT date, Patient ID, etc.)\n",
    "```\n",
    "n = 1\n",
    "for index,row in df.sample(frac=1)[:100].iterrows():\n",
    "    print(f\"Row Number: {n}\")\n",
    "    print(f\"Note: {row['ReportText']}\")\n",
    "    print('-'*100)\n",
    "    n+=1\n",
    "```\n",
    "##### Once a template is identified, modify the `pattern` variable in `extract_fev1_context` to match the beginning phrases or characters identified in the template (for example: `'Spirometry Interpretation:'`, and the approximate number of characters after the template start phrase that would include the variables of interest (this is in the format `{0,n}` where `n` is the desired length of the snippet in characters after the template start phrase. The template start phrase will be included in the snippet. You may optionally include `.{0,n}` directly prior to the template start phrase to include as many characters as you would like before the template start phrase. If you identify multiple possible template start phrases, you may employ the pipe operator (`|`) directly after the first template start phrase and add another template start phrase with the same format after the pipe operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20a96a2-c54b-4f63-9bf5-749326247797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create snippet based on template start phrases\n",
    "def extract_fev1_context(text):\n",
    "    pattern = re.compile(r'.Pulmonary Function Tests:.{0,350}|.Spirometry Interpretation.{0,350}', re.IGNORECASE)\n",
    "    matches = pattern.findall(text)\n",
    "    return ' '.join(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc2a71-fdc0-492c-8656-6e0198c364cb",
   "metadata": {},
   "source": [
    "## Step 4: Generate `Snippet` column by applying the `extract_fev1_context()` function to the `ReportText` column\n",
    "##### Here, we run the `ReportText` column through the snippet generation function and create a new column called `Snippet` which holds that value. First, we create a copy of the dataframe to prevent a `FutuerWarning` from appearing. Then, create the new column and initialize a new dataframe called `notes_with_fev` which keep only rows with an identified snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ccfb6fb-263b-4527-9ae9-4506ad9a2d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create 'Snippet' column based on 'ReportText' column in original dataframe by running the ReportText values through the function\n",
    "df = df.copy(deep = True)\n",
    "df['Snippet'] = df['ReportText'].apply(extract_fev1_context)\n",
    "\n",
    "# Create new dataframe where all rows with no snippet are dropped\n",
    "notes_with_fev = df[df['Snippet'] != ''].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692be238-8c0e-48bc-9c03-1550f79dcb83",
   "metadata": {},
   "source": [
    "##### As in the previous step, you can check the snippet results against the ReportText to make sure the function is capturing the accurate text fragments of adequate lengths.\n",
    "```\n",
    "n = 1\n",
    "for index,row in notes_with_fev.sample(frac=1)[:100].iterrows():\n",
    "    print(f\"Row Number: {n}\")\n",
    "    print(f\"Note: {row['ReportText']}\")\n",
    "    print(f\"Note: {row['Snippet']}\")\n",
    "    print('-'*100)\n",
    "    n+=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260a366-3816-46e9-986a-4a22ff57f5a5",
   "metadata": {},
   "source": [
    "## Step 5: Initialize Function to Classify PFT Results \n",
    "##### The below function employs regular expressions to extract specific PFT values from snippets and appends the results to the relevant lists. You may alter the names of variables, adapt regex matching patterns to identify and extract new or different values, or change the number of values per variable extracted. The function reads snippets from `notes_with_fev` on a row-by-row basis, and returns each extracted value as a pandas Series from a dictionary of the desired new column name as the key and new variable generated previously in the function as the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa42204-7685-4420-bf2f-4c3285ee1a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def classify_fev1(row):\n",
    "    \n",
    "    # Initialize variables of interest as lists to hold extracted values\n",
    "    fev1_abs_pre = []\n",
    "    fev1_abs_post = []\n",
    "    fev1_perc_predicted_pre = []\n",
    "    fev1_perc_predicted_post = []\n",
    "    fev1_fvc_pre = []\n",
    "    fev1_fvc_post = []\n",
    "    \n",
    "    text = row['Snippet']\n",
    "    \n",
    "    # FEV1 absolute value pre BD\n",
    "    fev1_abs_pre_pattern = re.compile(r'FEV1.*?(\\d*\\.\\d+)L?/\\d{2}', re.IGNORECASE)\n",
    "    fev1_abs_pre_pattern_results = fev1_abs_pre_pattern.findall(text)\n",
    "    \n",
    "    if fev1_abs_pre_pattern_results:\n",
    "        fev1_abs_pre.append(fev1_abs_pre_pattern_results[0])\n",
    "        \n",
    "    # FEV1 absolute value post BD\n",
    "    fev1_abs_post_pattern = re.compile(r'post BD\\s(\\d*\\.\\d+)L?/\\d{2}', re.IGNORECASE)\n",
    "    fev1_abs_post_pattern_results = fev1_abs_post_pattern.findall(text)\n",
    "    \n",
    "    if fev1_abs_post_pattern_results:\n",
    "        fev1_abs_post.append(fev1_abs_post_pattern_results[0])\n",
    "        \n",
    "    \n",
    "    # FEV1 Percent Predicted pre BD\n",
    "    fev1_perc_pred_pre = re.compile(r'FEV1.*?\\d*\\.\\d+L?/(\\d{2})', re.IGNORECASE)\n",
    "    fev1_perc_pred_pre_results = fev1_perc_pred_pre.findall(text)\n",
    "\n",
    "    if fev1_perc_pred_pre_results:\n",
    "        fev1_perc_predicted_pre.append(fev1_perc_pred_pre_results[0])\n",
    "        \n",
    "    # FEV1 Percent Predicted post BD\n",
    "    fev1_perc_pred_post = re.compile(r'post BD\\s\\d*\\.\\d+L?/(\\d{2})', re.IGNORECASE)\n",
    "    fev1_perc_pred_post_results = fev1_perc_pred_post.findall(text)\n",
    "\n",
    "    if fev1_perc_pred_post_results:\n",
    "        fev1_perc_predicted_post.append(fev1_perc_pred_post_results[0])\n",
    "        \n",
    "    # FEV1/FVC pre BD\n",
    "    fev1_fvc_pre_pattern = re.compile(r'''FEV1/FVC.*?\\d*\\.\\d+L?/\n",
    "                                      \\d{2}\\s\\d*\\.\\d+L?/\\d{2}\\s(\\d{2})'''\n",
    "                                      , re.IGNORECASE)\n",
    "    fev1_fvc_pre_results = fev1_fvc_pre_pattern.findall(text)\n",
    "\n",
    "    if fev1_fvc_pre_results:\n",
    "        fev1_fvc_pre.append(fev1_fvc_pre_results[0])\n",
    "        \n",
    "    # FEV1/FVC post BD \n",
    "    fev1_fvc_post_pattern = re.compile(r'''post BD\\s\\d*\\.\\d+L?/\n",
    "                                       \\d{2}\\s\\d*\\.\\d+L?/\\d{2}\\s(\\d{2})'''\n",
    "                                       , re.IGNORECASE)\n",
    "    fev1_fvc_post_results = fev1_fvc_post_pattern.findall(text)\n",
    "\n",
    "    if fev1_fvc_post_results:\n",
    "        fev1_fvc_post.append(fev1_fvc_post_results[0])\n",
    "     \n",
    "    # Initialize positive qualitative descriptor variable\n",
    "    fev1_qual_hi = []\n",
    "    \n",
    "    # Pattern matches for positive descriptors of FEV\n",
    "    fev1_qual_hi_pattern = re.compile(r'''(no obstructive ventilatory defect|\n",
    "                                          normal spirometry|no obstruction|\n",
    "                                          non-specific ventilatory)'''\n",
    "                                      , re.IGNORECASE)                                  \n",
    "    fev1_qual_hi_matches = fev1_qual_hi_pattern.findall(text)\n",
    "\n",
    "    # Append positive matches to list variable\n",
    "    for match in fev1_qual_hi_matches:\n",
    "        if len(match) > 0:\n",
    "            fev1_qual_hi.append(match)\n",
    "    \n",
    "    # Initialize negative qualitative descriptor variable\n",
    "    fev1_qual_lo = []\n",
    "    \n",
    "    # Pattern matches for negative descriptors of FEV\n",
    "    fev1_qual_lo_pattern = re.compile(r'''\n",
    "                                      (mild obstructive defect|\n",
    "                                       mild obstructive ventilatory defect|\n",
    "                                       moderately severe obstructive ventilatory defect|\n",
    "                                       very severe obstructive ventilatory defect|\n",
    "                                       very severe obstruction ventilatory defect|\n",
    "                                       severe obstructive ventilatory defect|\n",
    "                                       moderate severe obstructive ventilatory defect|\n",
    "                                       mild obstruction|moderate obstruction|\n",
    "                                       severe obstruction|\n",
    "                                       moderately severe obstructive ventilatory defect)\n",
    "                                       '''\n",
    "                                      , re.IGNORECASE)\n",
    "    fev1_qual_lo_matches = fev1_qual_lo_pattern.findall(text)\n",
    "    \n",
    "    # Append negative matches to list variable\n",
    "    for match in fev1_qual_lo_matches:\n",
    "        if len(match) > 0:\n",
    "            fev1_qual_lo.append(match)\n",
    "    \n",
    "    # If previously identified negative match, negative match supercedes positive\n",
    "    if len(fev1_qual_lo) != 0:\n",
    "        fev1_qual_hi = []\n",
    "    \n",
    "    '''\n",
    "    Return the results of the above capturing patterns as Series, \n",
    "    which are joined to the original dataframe as new columns row-wise. \n",
    "    Names are modifiable.\n",
    "    '''\n",
    "    return pd.Series({'FEV1_Abs_Pre': fev1_abs_pre if fev1_abs_pre else None,\n",
    "                      'FEV1_Perc_Pred_Pre': fev1_perc_predicted_pre if fev1_perc_predicted_pre else None,\n",
    "                      'FEV1_FVC_Pre': fev1_fvc_pre if fev1_fvc_pre else None,\n",
    "                      'FEV1_Abs_Post': fev1_abs_post if fev1_abs_post else None,\n",
    "                      'FEV1_Perc_Pred_Post': fev1_perc_predicted_post if fev1_perc_predicted_post else None,\n",
    "                      'FEV1_FVC_Post': fev1_fvc_post if fev1_fvc_post else None,\n",
    "                      'FEV1_Qual_High': fev1_qual_hi if fev1_qual_hi else None,\n",
    "                      'FEV1_Qual_Low': fev1_qual_lo if fev1_qual_lo else None})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef85f1a4-ba06-450b-9bac-c9c143cb0507",
   "metadata": {},
   "source": [
    "## Step 6: Run dataframe through the PFT extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2a14f07-8018-4ae6-8a05-b28a1a42c6d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Initialize a new dataframe called 'results' which\n",
    "adds the new variables as columns to the original dataframe\n",
    "'''\n",
    "results = notes_with_fev.join(notes_with_fev.apply(classify_fev1, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31a0a1-ee49-40d7-ac23-a597767a32e6",
   "metadata": {},
   "source": [
    "## Step 7: Extract values from FEV1 % predicted, FEV1:FVC pre-BD, and qualitative variables.\n",
    "##### These values are stored as nested lists, so we need to apply a function that extracts the value via indexing and converts it to either an integer (quantitative) or string (qualitative) for later processing. These values are stored in new variables added to the `results` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43b2665e-ece9-489a-9f71-c85e2e9097ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_value(nested_list):\n",
    "    if nested_list is not None:\n",
    "        return int(nested_list[0])\n",
    "    \n",
    "# Create new variables 'FEV1_Perc_Pred' and 'fev1_fvc' to hold extracted quantitative values\n",
    "results['FEV1_Percent_Pred'] = results['FEV1_Perc_Pred_Pre'].apply(extract_value)\n",
    "results['fev1_fvc'] = results['FEV1_FVC_Pre'].apply(extract_value)\n",
    "\n",
    "def extract_fev1_qualitative(nested_list):\n",
    "    if nested_list is not None:\n",
    "        return str(nested_list[0])\n",
    "\n",
    "# Create new variables to hold qualitative data\n",
    "results['fev1_qual_neg'] = results['FEV1_Qual_Low'].apply(extract_fev1_qualitative)\n",
    "results['fev1_qual_pos'] = results['FEV1_Qual_High'].apply(extract_fev1_qualitative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6822a73e-1104-4bed-b49d-adddceef9bf5",
   "metadata": {},
   "source": [
    "## Step 8: Create mapping functions to map quantitative values to the standard clinical definitions of obstruction and severity of obstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "330e45ed-4b83-4f25-b18c-b93ced9a66ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create mapping function\n",
    "def fev1_severity(value):\n",
    "    if value >= 80:\n",
    "        return \"Normal\"\n",
    "    if 70 <= value <= 79:\n",
    "        return \"Mild\"\n",
    "    if 60 <= value <= 69:\n",
    "        return \"Moderate\"\n",
    "    if 50 <= value <= 59:\n",
    "        return \"Moderately Severe\"\n",
    "    if 35 <= value < 50:\n",
    "        return \"Severe\"\n",
    "    if value < 35:\n",
    "        return \"Very Severe\"\n",
    "    \n",
    "def obstruction(value):\n",
    "    if value >= 70:\n",
    "        return \"Normal\"\n",
    "    if value < 70:\n",
    "        return \"Reduced\"\n",
    "\n",
    "# Create new variables 'FEV1_Severity' and 'Obstruction' by running the FEV1 % predicted and FEV1:FVC variables through the mapping functions\n",
    "results['FEV1_Severity'] = results['FEV1_Percent_Pred'].map(fev1_severity)\n",
    "results['Obstruction'] = results['fev1_fvc'].map(obstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64526fc6-8a9b-448d-9479-fd55c34ea482",
   "metadata": {},
   "source": [
    "## Step 9a: Impute FEV1 severity values from qualitative data\n",
    "##### This function assigns values to the `FEV1_Severity` variable created in the previous step, based on qualitative data in note snippets. The value is only imputed if the quantitative mapping function produced no FEV1 severity results, indicating that, for that row, no quantitative value for FEV1 severity was extracted from the templated note snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c050daf8-5770-4526-8d50-dfde54d73ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fev1_severity_from_qual(row):\n",
    "    if row['FEV1_Severity'] is None and row['fev1_qual_pos'] in ['Normal spirometry', 'normal spirometry']:\n",
    "        return \"Normal\"\n",
    "    if row['FEV1_Severity'] is None and row['fev1_qual_neg'] in ['mild obstructive ventilatory defect', \n",
    "                                                                 'Mild obstructive ventilatory defect', \n",
    "                                                                 'mild obstructive defect']:\n",
    "        return \"Mild\"\n",
    "    elif row['FEV1_Severity'] is None and row['fev1_qual_neg'] in ['moderate obstructive ventilatory defect', \n",
    "                                                                   'Moderate obstructive ventilatory defect']:\n",
    "        return \"Moderate\"\n",
    "    elif row['FEV1_Severity'] is None and row['fev1_qual_neg'] in ['moderately severe obstructive ventilatory defect', \n",
    "                                                                   'Moderately severe obstructive ventilatory defect', \n",
    "                                                                   'Moderate severe obstructive ventilatory defect', \n",
    "                                                                   'moderate severe obstructive ventilatory defect']:\n",
    "        return \"Moderately Severe\"\n",
    "    elif row['FEV1_Severity'] is None and row['fev1_qual_neg'] not in ['moderately severe obstructive ventilatory defect', \n",
    "                                                                       'Moderately severe obstructive ventilatory defect', \n",
    "                                                                       'Moderate severe obstructive ventilatory defect', \n",
    "                                                                       'moderate severe obstructive ventilatory defect'] \n",
    "                                                                        and row['fev1_qual_neg'] in \n",
    "                                                                        ['severe obstructive ventilatory defect', \n",
    "                                                                         'Severe obstructive ventilatory defect', \n",
    "                                                                         'severe obstruction']:\n",
    "        return \"Severe\"\n",
    "    elif row['FEV1_Severity'] is None and row['fev1_qual_neg'] not in ['moderately severe obstructive ventilatory defect', \n",
    "                                                                       'Moderately severe obstructive ventilatory defect', \n",
    "                                                                       'Moderate severe obstructive ventilatory defect', \n",
    "                                                                       'moderate severe obstructive ventilatory defect'] \n",
    "                                                                        and row['fev1_qual_neg'] not in \n",
    "                                                                        ['severe obstructive ventilatory defect', \n",
    "                                                                         'Severe obstructive ventilatory defect', \n",
    "                                                                         'severe obstruction'] \n",
    "                                                                        and row['fev1_qual_neg'] in \n",
    "                                                                        ['Very severe obstructive ventilatory defect', \n",
    "                                                                         'very severe obstructive ventilatory defect', \n",
    "                                                                         'Very severe obstruction ventilatory defect']:\n",
    "        return \"Very Severe\"\n",
    "    else:\n",
    "        return row['FEV1_Severity']\n",
    "\n",
    "# If quantitative data is missing for FEV1 % predicted, use qualitative data to map value\n",
    "results['FEV1_Severity'] = results.apply(fev1_severity_from_qual, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad0a8e-03d2-4e21-a0bc-9b4a472df278",
   "metadata": {},
   "source": [
    "## Step 9b: Impute obstruction values from qualitative data\n",
    "##### This function assigns values to the `Obstruction` variable created in the previous step, based on qualitative data in note snippets. The value is only imputed if the quantitative mapping function produced no results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c0bb371-d2f1-479b-b954-cf64d41b1253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def obstruction_from_qual(row):\n",
    "    if row['Obstruction'] is None and row['fev1_qual_pos'] in ['No obstructive ventilatory defect', \n",
    "                                                               'no obstructive ventilatory defect', \n",
    "                                                               'normal spirometry', \n",
    "                                                               'Normal spirometry', \n",
    "                                                               'No obstruction', \n",
    "                                                               'no obstruction', \n",
    "                                                               'non-specific ventilatory']:\n",
    "        return \"Normal\"\n",
    "    elif row['Obstruction'] is None and row['fev1_qual_neg'] is not None:\n",
    "        return \"Reduced\"\n",
    "    else:\n",
    "        return row['Obstruction']\n",
    "    \n",
    "# If quantitative data is missing for Obstruction, use qualitative data to map value\n",
    "results['Obstruction'] = results.apply(obstruction_from_qual, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a9b46-7511-4e44-a3bb-e3482c19dfb7",
   "metadata": {},
   "source": [
    "## Step 10: Drop duplicate rows or rows missing extracted PFT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d99fe1a-0350-4a40-adba-527f8b924e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List columns to define on which variables you would like to drop duplicates\n",
    "list_cols = ['Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', \n",
    "             'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post', \n",
    "             'FEV1_Qual_High', 'FEV1_Qual_Low']\n",
    "\n",
    "# Drop rows that have no extracted PFT values\n",
    "results = results.dropna(subset = list_cols, how = 'all')\n",
    "\n",
    "# Convert columns in list_cols to string\n",
    "for col in list_cols:\n",
    "    results[col] = results[col].apply(lambda x: str(x))\n",
    "    \n",
    "# Drop duplicates of PFT results based on columns of interest + PatientID and PFT date\n",
    "results = results.drop_duplicates(subset = ['PatientICN', 'pft_date', 'Obstruction', \n",
    "                                            'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', \n",
    "                                            'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', \n",
    "                                            'FEV1_FVC_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low'])\n",
    "\n",
    "# Replace cells with 'None' values to empty string for ease of readability in the output Excel file\n",
    "results.replace('None','',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27af347-0246-4319-8599-bd3a6b4d23e7",
   "metadata": {},
   "source": [
    "## Step 11: Merge rows from same PFT with multiple notes containing values for different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95397192-9dd3-4db1-b881-a9d293121f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define columns that will keep the max value if the two rows being merged have different values for.\n",
    "columns_to_max = ['PatientSID', 'Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', \n",
    "                  'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low']\n",
    "\n",
    "# This function ensures that we don't lose one of the snippets upon merge, but rather append them together\n",
    "def concatenate_strings(series):\n",
    "    return ''.join(series.unique())\n",
    "\n",
    "# Define aggregation function to keep the max value for columns that both have data across the rows\n",
    "agg_funcs = {col: 'max' for col in columns_to_max}\n",
    "\n",
    "# Create concatenated snippets for merged rows (instead of taking the \"max\" snippet value)\n",
    "agg_funcs['Snippet'] = concatenate_strings\n",
    "\n",
    "# Regenerate dataframe with collapsed rows for identical PFTs with multiple notes\n",
    "results = results.groupby(['PatientICN','pft_date'], sort = False).agg(agg_funcs).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69033947-c551-4db7-9a6e-2a6db76021d2",
   "metadata": {},
   "source": [
    "## Step 12: Export data to Excel for validation/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48984f25-51e7-4eb1-b8b9-641a12c91173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select columns to export\n",
    "columns_to_export = ['Snippet', 'PatientICN', 'PatientSID', 'pft_date', \n",
    "                     'Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', \n",
    "                     'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', \n",
    "                     'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post', 'FEV1_Qual_High', 'FEV1_Qual_Low']\n",
    "\n",
    "# Define desired output directory, file name, and file path\n",
    "output_dir = '[Insert Output Directory Here]/'\n",
    "file_name = '[Insert Output File Name Here].xlsx'\n",
    "full_path = output_dir + file_name\n",
    "to_export = results\n",
    "\n",
    "# Export data as .xlsx file\n",
    "to_export.to_excel(full_path, columns = columns_to_export, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
