{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "603dadec-d73e-4ce2-aac3-17e7755950c4",
   "metadata": {},
   "source": [
    "## Step 1: Import packages\n",
    "##### First, import the necessary Python libraries. This method only requires the pandas and re packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87da6e46-ee07-4f0c-bc45-0d0745a9dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba1935-5f3b-4dbf-8f61-81957cfff5a4",
   "metadata": {},
   "source": [
    "## Step 2: Import dataset and perform initial preprocessing steps\n",
    "##### The next piece of code accomplishes several important preprocessing steps. First, we read the dataset into a pandas dataframe from Excel. Next, we'll convert the ReportText column to string and convert any contiguous spaces or carriage returns to a single space. This transforms the ReportText column into a much more readable format for identifying PFT report templates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b7c52c-db8b-4170-897f-5c99532fdecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import data from Excel to pandas dataframe. Important to include PatientICN, PFT date, and ReportText columns\n",
    "df = pd.read_excel('[Insert Directory Here]/[Insert File Name Here].xlsx')\n",
    "\n",
    "# Convert ReportText to string and remove carriage returns and extra spacing between words\n",
    "df['ReportText'] = df['ReportText'].astype('str')\n",
    "df['ReportText'] = df['ReportText'].str.replace(r'\\s+', ' ', regex=True).str.replace(r'\\n+', ' ', regex=True)\n",
    "\n",
    "# Convert PFT date column to date data type\n",
    "df['pft_date'] = df['pft_date'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7cfbca-f5ca-4872-a4a6-946380fbc241",
   "metadata": {},
   "source": [
    "## Step 3: Create function to generate snippets from notes\n",
    "##### In order to do identify templates, use the following code to investigate the a random sample of 100 notes with a record counter and '-'-' separator for readability. You must identify templates before moving onto the next step, where you create the function `extract_fev1_context()`. Feel free to add additional columns to the below loop for more thorough validation (e.g. PFT date, Patient ID, etc.)\n",
    "```\n",
    "n = 1\n",
    "for index,row in df.sample(frac=1)[:100].iterrows():\n",
    "    print(f\"Row Number: {n}\")\n",
    "    print(f\"Note: {row['ReportText']}\")\n",
    "    print('-'*100)\n",
    "    n+=1\n",
    "```\n",
    "##### Once a template is identified, modify the `pattern` variable in `extract_fev1_context` to match the beginning phrases or characters identified in the template (for example: `'Spirometry Interpretation:'`, and the approximate number of characters after the template start phrase that would include the variables of interest (this is in the format `{0,n}` where `n` is the desired length of the snippet in characters after the template start phrase. The template start phrase will be included in the snippet. You may optionally include `.{0,n}` directly prior to the template start phrase to include as many characters as you would like before the template start phrase. If you identify multiple possible template start phrases, you may employ the pipe operator (`|`) directly after the first template start phrase and add another template start phrase with the same format after the pipe operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c64a3e-6e1e-4a4b-a6b6-df4eea99c189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create snippet based on template start phrases\n",
    "def extract_fev1_context(text):\n",
    "    pattern = re.compile(r'.[Insert Template Start Phrase].{0,n}|.[Optional Second Template Start Phrase].{0,n}', re.IGNORECASE)\n",
    "    matches = pattern.findall(text)\n",
    "    return ' '.join(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f18c21-24f9-40c6-9b0c-57ece0203fe4",
   "metadata": {},
   "source": [
    "##### Example of inclusion of characters before template start phrase\n",
    "```\n",
    "def extract_fev1_context(text):\n",
    "    pattern = re.compile(r'.{0,n}[Insert Template Start Phrase].{0,n}|.[Optional Second Template Start Phrase].{0,n}', re.IGNORECASE)\n",
    "    matches = pattern.findall(text)\n",
    "    return ' '.join(matches)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e4a0d-2da4-4f16-a703-ac02fea99f74",
   "metadata": {},
   "source": [
    "## Step 4: Generate `Snippet` column by applying the `extract_fev1_context()` function to the `ReportText` column\n",
    "##### Here, we run the `ReportText` column through the snippet generation function and create a new column called `Snippet` which holds that value. First, we create a copy of the dataframe to prevent a `FutuerWarning` from appearing. Then, create the new column and initialize a new dataframe called `notes_with_fev` which keep only rows with an identified snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03a3c0a-5b64-4ae1-99ad-ba29fde597da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create 'Snippet' column based on 'ReportText' column in original dataframe by running the ReportText values through the function\n",
    "df = df.copy(deep = True)\n",
    "df['Snippet'] = df['ReportText'].apply(extract_fev1_context)\n",
    "\n",
    "# Create new dataframe where all rows with no snippet are dropped\n",
    "notes_with_fev = df[df['Snippet'] != ''].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5f308-f669-4dba-8e83-5b6c4f3e6619",
   "metadata": {},
   "source": [
    "##### As in the previous step, you can check the snippet results against the ReportText to make sure the function is capturing the accurate text fragments of adequate lengths.\n",
    "```\n",
    "n = 1\n",
    "for index,row in notes_with_fev.sample(frac=1)[:100].iterrows():\n",
    "    print(f\"Row Number: {n}\")\n",
    "    print(f\"Note: {row['ReportText']}\")\n",
    "    print(f\"Note: {row['Snippet']}\")\n",
    "    print('-'*100)\n",
    "    n+=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb99a53-e401-4baa-aed3-52188187acc9",
   "metadata": {},
   "source": [
    "## Step 5: Initialize Function to Classify PFT Results\n",
    "##### The below function employs regular expressions to extract specific PFT values from snippets and appends the results to the relevant lists. You may alter the names of variables, adapt regex matching patterns to identify and extract new or different values, or change the number of values per variable extracted. The function reads snippets from `notes_with_fev` on a row-by-row basis, and returns each extracted value as a pandas Series from a dictionary of the desired new column name as the key and new variable generated previously in the function as the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90cde959-25c1-4ffe-a758-b3f8d18bf0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to classify PFT results. Regexes are used to extract values based on the identified snippets.\n",
    "def classify_fev1(row):\n",
    "    \n",
    "    # Initialize variables of interest as lists to hold extracted values\n",
    "    fev1_abs_post = []\n",
    "    fev1_abs_pre = []\n",
    "    fev1_fvc_pre = []\n",
    "    fev1_fvc_post = []\n",
    "    fev1_perc_predicted_post = []\n",
    "    fev1_perc_predicted_pre = []\n",
    "    \n",
    "    # Extract the snippet from each row\n",
    "    text = row['Snippet']\n",
    "    \n",
    "    # FEV1 pre-BD absolute value pattern\n",
    "    fev1_vol_pre = re.compile(r'FEV1(?:-Pre)\\:\\s(\\d*\\.\\d+)\\s?L?', re.IGNORECASE)\n",
    "    fev1_vol_pre_results = fev1_vol_pre.findall(text)\n",
    "    \n",
    "    if fev1_vol_pre_results:\n",
    "        fev1_abs_pre.append(fev1_vol_pre_results)\n",
    "    \n",
    "    # FEV1 post-BD absolute value matching pattern\n",
    "    fev1_vol_post = re.compile(r'FEV1(?:-Post)\\:\\s(\\d*\\.\\d+)\\s?L?', re.IGNORECASE)\n",
    "    fev1_vol_post_results = fev1_vol_post.findall(text)\n",
    "    \n",
    "    if fev1_vol_post_results:\n",
    "        fev1_abs_post.append(fev1_vol_post_results)\n",
    "      \n",
    "    # FEV1/FVC pre-BD\n",
    "    fev1_fvc_pre_pattern = re.compile(r'FEV1(?:FVC-Pre)\\:\\s(\\d{2,3})', re.IGNORECASE)\n",
    "    fev1_fvc_pre_pattern_results = fev1_fvc_pre_pattern.findall(text)\n",
    "                                  \n",
    "    if fev1_fvc_pre_pattern_results:\n",
    "        fev1_fvc_pre.append(fev1_fvc_pre_pattern_results)\n",
    "        \n",
    "    # FEV1/FVC post-BD\n",
    "    fev1_fvc_post_pattern = re.compile(r'FEV1(?:FVC-Post)\\:\\s(\\d{2,3})', re.IGNORECASE)\n",
    "    fev1_fvc_post_pattern_results = fev1_fvc_post_pattern.findall(text)\n",
    "                                  \n",
    "    if fev1_fvc_post_pattern_results:\n",
    "        fev1_fvc_post.append(fev1_fvc_post_pattern_results)\n",
    "        \n",
    "    # FEV1 percent predicted pre-BD\n",
    "    fev1_perc_pred_pre = re.compile(r'FEV1(?:-%Pred-Pre)\\:\\s(\\d{2,3})', re.IGNORECASE)\n",
    "    fev1_perc_pred_pre_results = fev1_perc_pred_pre.findall(text)\n",
    "\n",
    "    if fev1_perc_pred_pre_results:\n",
    "        fev1_perc_predicted_pre.append(fev1_perc_pred_pre_results)\n",
    "    \n",
    "    # FEV1 percent predicted post-BD\n",
    "    fev1_perc_pred_post = re.compile(r'FEV1(?:-%Pred-Post)\\:\\s(\\d{2,3})', re.IGNORECASE)\n",
    "    fev1_perc_pred_post_results = fev1_perc_pred_post.findall(text)\n",
    "\n",
    "    if fev1_perc_pred_post_results:\n",
    "        fev1_perc_predicted_post.append(fev1_perc_pred_post_results)\n",
    "        \n",
    "    # Return the results of the above capturing patterns as Series, which are joined to the original dataframe as new columns row-wise. Names are modifiable.\n",
    "    return pd.Series({'FEV1_Abs_Post': fev1_abs_post if fev1_abs_post else None,\n",
    "                      'FEV1_Abs_Pre': fev1_abs_pre if fev1_abs_pre else None,\n",
    "                      'FEV1_FVC_Pre': fev1_fvc_pre if fev1_fvc_pre else None,\n",
    "                      'FEV1_FVC_Post': fev1_fvc_post if fev1_fvc_post else None,\n",
    "                      'FEV1_Perc_Pred_Post': fev1_perc_predicted_post if fev1_perc_predicted_post else None,\n",
    "                     'FEV1_Perc_Pred_Pre': fev1_perc_predicted_pre if fev1_perc_predicted_pre else None\n",
    "                     })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685db87-0e47-477a-bd95-2a87da0f42c3",
   "metadata": {},
   "source": [
    "## Step 6: Run dataframe through the PFT extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2cd184d-1c32-401b-9be6-439691ac8525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a new dataframe called 'results' which adds the new variables as columns to the original dataframe\n",
    "results = notes_with_fev.join(notes_with_fev.apply(classify_fev1, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e95c52e-8b84-451f-9926-8886fc9b593d",
   "metadata": {},
   "source": [
    "## Step 7: Extract values from FEV1 % predicted and FEV1:FVC pre-BD variables.\n",
    "##### These values are stored as nested lists, so we need to apply a function that extracts the value via indexing and converts it to integer for later processing. These values are stored in new variables added to the `results` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f40c483-2cd9-4eaf-89d6-3855a4aad386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create function to extract FEV1 % predicted and FEV1/FVC ratios from results\n",
    "def extract_value(nested_list):\n",
    "    if nested_list is not None:\n",
    "        return int(nested_list[0][0])\n",
    "    \n",
    "# Create new variables 'FEV1_Perc_Pred' and 'fev1_fvc' to hold extracted quantitative values\n",
    "results['FEV1_Perc_Pred'] = results['FEV1_Perc_Pred_Pre'].apply(extract_value)\n",
    "results['fev1_fvc'] = results['FEV1_FVC_Pre'].apply(extract_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b92b4-596c-4702-9ce0-bb7721067cd3",
   "metadata": {},
   "source": [
    "## Step 8: Create mapping functions to map quantitative values to the standard clinical definitions of obstruction and severity of obstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2d66039-feb6-4167-b84c-81020e26327f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create mapping functions for FEV1 Severity and Obstruction\n",
    "def fev1_severity(value):\n",
    "    if value >= 80:\n",
    "        return \"Normal\"\n",
    "    if 70 <= value <= 79:\n",
    "        return \"Mild\"\n",
    "    if 60 <= value <= 69:\n",
    "        return \"Moderate\"\n",
    "    if 50 <= value <= 59:\n",
    "        return \"Moderately Severe\"\n",
    "    if 35 <= value < 50:\n",
    "        return \"Severe\"\n",
    "    if value < 35:\n",
    "        return \"Very Severe\"\n",
    "    \n",
    "def obstruction(value):\n",
    "    if value >= 70:\n",
    "        return \"Normal\"\n",
    "    if value < 70:\n",
    "        return \"Reduced\"\n",
    "\n",
    "# Create new variables 'FEV1_Severity' and 'Obstruction' by running the FEV1 % predicted and FEV1:FVC variables through the mapping functions\n",
    "results['FEV1_Severity'] = results['FEV1_Perc_Pred'].map(fev1_severity)\n",
    "results['Obstruction'] = results['fev1_fvc'].map(obstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee3f74-478f-41ec-b271-19cf5c017603",
   "metadata": {},
   "source": [
    "## Step 9: Drop duplicate rows or rows missing extracted PFT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57bb72c2-7697-43a3-99b1-bb8c8cecf588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List columns to define on which variables you would like to drop duplicates\n",
    "list_cols = ['Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post']\n",
    "\n",
    "# Drop rows that have no extracted PFT values\n",
    "results = results.dropna(subset = list_cols, how = 'all')\n",
    "\n",
    "# Convert columns in list_cols to string\n",
    "for col in list_cols:\n",
    "    results[col] = results[col].apply(lambda x: str(x))\n",
    "    \n",
    "# Drop duplicates of PFT results based on columns of interest + PatientID and PFT date\n",
    "results = results.drop_duplicates(subset = ['PatientICN', 'pft_date', 'Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post'])\n",
    "\n",
    "# Replace cells with 'None' values to empty string for ease of readability in the output Excel file\n",
    "results.replace('None','',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9401cac4-e662-4495-a961-827ca41aeb26",
   "metadata": {},
   "source": [
    "## Step 10: Merge rows from same PFT with multiple notes containing values for different variables\n",
    "##### Due to the messiness of the note data, some identical PFTs have results for some variables in one note and results for other variables in a different note. This code combines these duplicates into single rows, keeping only the maximum value for each unique, non-duplicated variable. This applies to both quantitative and qualitative data, and since this is done after constructing the Obstruction and severity of obstruction variables, there is a small chance that the difference in quantitative vs. qualitative mapping results will lead to a correct result being replace with an incorrect result for those variables. This occurs at a very low rate, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897474e8-ba37-4cd5-bfd2-56899391146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns that will keep the max value if the two rows being merged have different values for.\n",
    "columns_to_max = ['PatientSID', 'Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post']\n",
    "\n",
    "# This function ensures that we don't lose one of the snippets upon merge, but rather append them together\n",
    "def concatenate_strings(series):\n",
    "    return ''.join(series.unique())\n",
    "\n",
    "# Define aggregation function to keep the max value for columns that both have data across the rows\n",
    "agg_funcs = {col: 'max' for col in columns_to_max}\n",
    "\n",
    "# Create concatenated snippets for merged rows (instead of taking the \"max\" snippet value)\n",
    "agg_funcs['Snippet'] = concatenate_strings\n",
    "\n",
    "# Regenerate dataframe with collapsed rows for identical PFTs with multiple notes\n",
    "results = results.groupby(['PatientICN','pft_date'], sort = False).agg(agg_funcs).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09c4a2-20a4-4b57-84f4-154046981e1a",
   "metadata": {},
   "source": [
    "## Step 11: Export data to Excel for validation/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac9d3bf-ab69-487f-8266-848277b6feae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select columns to export\n",
    "columns_to_export = ['Snippet', 'PatientICN', 'PatientSID', 'pft_date', 'Obstruction', 'FEV1_Severity', 'FEV1_Abs_Pre', 'FEV1_Perc_Pred_Pre', 'FEV1_FVC_Pre', 'FEV1_Abs_Post', 'FEV1_Perc_Pred_Post', 'FEV1_FVC_Post']\n",
    "\n",
    "# Define desired output directory, file name, and file path\n",
    "output_dir = '[Insert Output Directory Here]/'\n",
    "file_name = '[Insert Output File Name Here].xlsx'\n",
    "full_path = output_dir + file_name\n",
    "to_export = results\n",
    "\n",
    "# Export data as .xlsx file\n",
    "to_export.to_excel(full_path, columns = columns_to_export, index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
